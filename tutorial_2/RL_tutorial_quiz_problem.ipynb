{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pidipidi/CS470_IAI_2024_Fall/blob/main/tutorial_2/RL_tutorial_quiz_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "fdSOfUuN4w8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Please run this tutorial on Google Chrome.\n",
        "\n",
        "[https://www.google.com/chrome](https://www.google.com/chrome)\n",
        "\n",
        "\n",
        "The tutorial may not work properly if you use a browser other than Google Chrome"
      ],
      "metadata": {
        "id": "xCTRK3XdfR-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the following commands to install dependencies\n",
        "#Install dependencies for OpenAI Gym and Stable-baselines3\n",
        "!apt install swig cmake &> /dev/null\n",
        "!pip install stable_baselines3 &> /dev/null\n",
        "!pip install gymnasium[classic_control] &> /dev/null\n",
        "\n",
        "\n",
        "#Install dependencies to visualize agents\n",
        "!apt-get install -y xvfb &> /dev/null\n",
        "!pip install pyvirtualdisplay scikit-video ffio pyrender &> /dev/null\n",
        "import os\n",
        "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "KRS9SfsG3DF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the following commands to define visualization tools\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "\n",
        "import skvideo.io\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "def save_video_of_model(env_name, policy=None, suffix=\"\"):\n",
        "    \"\"\"Record an agent behavior in an input environment\"\"\"\n",
        "\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "    obs = env.reset()[0]\n",
        "    prev_obs = obs\n",
        "\n",
        "    filename = env_name + suffix + \".mp4\"\n",
        "    output_video = skvideo.io.FFmpegWriter(filename)\n",
        "\n",
        "    counter = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        frame = env.render()\n",
        "        output_video.writeFrame(frame)\n",
        "\n",
        "        input_obs = obs\n",
        "\n",
        "        if policy is not None:\n",
        "            action = policy(input_obs)\n",
        "\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "\n",
        "        if \"FrozenLake\" in env_name:\n",
        "            action = action.item()\n",
        "        prev_obs = obs\n",
        "\n",
        "        obs, reward, done, _, info = env.step(action)\n",
        "        counter += 1\n",
        "\n",
        "    output_video.close()\n",
        "    print(\"Successfully saved {} frames into {}!\".format(counter, filename))\n",
        "    return filename\n",
        "\n",
        "def play_video(filename, width=None):\n",
        "    \"\"\"Play the filename of video\"\"\"\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "\n",
        "    mp4 = open(filename,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    source = \"\"\"\n",
        "    <video width=400 controls>\n",
        "          <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url\n",
        "    return source\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "\n",
        "def my_seed_everywhere(seed: int = 42):\n",
        "    random.seed(seed) # random\n",
        "    np.random.seed(seed) # numpy\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed) # os\n",
        "    # pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "my_seed = 42\n",
        "my_seed_everywhere(my_seed)"
      ],
      "metadata": {
        "id": "GhmNo6uu-Z4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CartPole-v0 environment"
      ],
      "metadata": {
        "id": "61wEJLl31hC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this quiz, we will use CartPole-v0 environment. This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson in “Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem”. A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces in the left and right direction on the cart.\n",
        "\n",
        "https://gymnasium.farama.org/environments/classic_control/cart_pole/"
      ],
      "metadata": {
        "id": "-5lEqvTp1zTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cp.gif](data:image/gif;base64,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)"
      ],
      "metadata": {
        "id": "YtJJKTe01qHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Please choose the pair that properly describes the class of (observation_space, action_space) of \"CartPole-v1\".\n",
        "\n",
        "\n",
        "\n",
        "1.   (Discrete, Discrete)\n",
        "2.   (Box, Discrete)\n",
        "3.   (Discrete, Box)\n",
        "4.   (Box, Box)\n",
        "\n",
        "\n",
        "You may use the cell below to find the answer"
      ],
      "metadata": {
        "id": "2nrkHYAdOXZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "#print( env.? )\n",
        "#print( env.? )"
      ],
      "metadata": {
        "id": "SpgvdK9G5KWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Please choose the pair that properly fills in the sentence.\n",
        "\n",
        "We use {$\\qquad$} method to initialize or restart the environment. If we initialize \"CartPole-v1\" environment, the **first** element of the initial state fall within {$\\qquad$} range.\n",
        "\n",
        "\n",
        "1.   (step, [-1.0, 1.0])\n",
        "2.   (reset, [-0.05, 0.05])\n",
        "3.   (reset, [-4.8, 4.8])\n",
        "4.   (step, [-0.05, 0.05])\n",
        "\n",
        "\n",
        "You may use the cell below to find the answer"
      ],
      "metadata": {
        "id": "xKXq15FUGo_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "#print(env.?)"
      ],
      "metadata": {
        "id": "439qmdPeGo2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Please choose the answer that correctly estimates the maximum total reward of \"CartPole-v1\" environment.\n",
        "\n",
        "\n",
        "1.   around 110\n",
        "2.   around 250\n",
        "3.   around 470\n",
        "4.   around 700\n",
        "\n",
        "\n",
        "You may use the cell below to find the answer.\n",
        "\n",
        "You may increase (decrease) the total_timestep value if you think the agent has not trained enough (has trained enough)."
      ],
      "metadata": {
        "id": "LJ-piSTT0gyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import stable_baselines3\n",
        "from stable_baselines3 import PPO, DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "######################################################################\n",
        "##  You can choose your Algorithm / Environment / seed as you want  ##\n",
        "######################################################################\n",
        "\n",
        "policy_cls = PPO\n",
        "env_id = \"CartPole-v1\"\n",
        "SEED = 47\n",
        "\n",
        "######################################################################\n",
        "######################################################################\n",
        "\n",
        "\n",
        "# Use a separate environement for evaluation\n",
        "env = gym.make(env_id)\n",
        "eval_env = gym.make(env_id)\n",
        "# Initialize Agent, which is currently an random Agent, before training\n",
        "model = policy_cls(policy='MlpPolicy',      # For vision-based RL, we use 'CnnPolicy'\n",
        "            env=env,\n",
        "            seed=SEED,\n",
        "            gamma=0.9)"
      ],
      "metadata": {
        "id": "KaI-zqzy5oQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps, EvalCallback\n",
        "\n",
        "rewards = []\n",
        "class CB(EvalCallback):\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.eval_freq == 0:\n",
        "            mean_reward, std_reward = evaluate_policy(self.model, self.eval_env, n_eval_episodes=5)\n",
        "            rewards.append(mean_reward)\n",
        "            print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "        return True\n",
        "\n",
        "cb = CB(eval_env=eval_env, eval_freq=10000)\n",
        "model.learn(total_timesteps=100000, callback=cb)\n"
      ],
      "metadata": {
        "id": "cVlwqTeMZzip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "id": "CB13iS3c0X3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(env_id, render_mode=\"rgb_array\")\n",
        "obs = env.reset()[0]\n",
        "prev_obs = obs\n",
        "\n",
        "policy=lambda *x: model.predict(*x)[0]\n",
        "\n",
        "counter = 0\n",
        "done = False\n",
        "while not done:\n",
        "    frame = env.render()\n",
        "    input_obs = obs\n",
        "\n",
        "    if policy is not None:\n",
        "        action = policy(input_obs)\n",
        "\n",
        "    else:\n",
        "        action = env.action_space.sample()\n",
        "\n",
        "    if \"FrozenLake\" in env_id:\n",
        "        action = action.item()\n",
        "    prev_obs = obs\n",
        "\n",
        "    obs, reward, done, _, info = env.step(action)\n",
        "    counter += 1"
      ],
      "metadata": {
        "id": "-NAr_LcCzUgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_video_of_model(env_id, policy=lambda *x: model.predict(*x)[0])\n",
        "\n",
        "from IPython.display import HTML\n",
        "source = play_video(filename=f'{env_id}.mp4')\n",
        "HTML(source)"
      ],
      "metadata": {
        "id": "b5aRRAhvbH8n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
